{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "import rasterio\n",
    "from pathlib import Path\n",
    "from collections import deque\n",
    "from rasterio.transform import rowcol\n",
    "from rasterio.mask import mask\n",
    "from google.colab import drive\n",
    "from osgeo import gdal\n",
    "import numpy as np\n",
    "\n",
    "# Mount Google drive to colab runtime.\n",
    "drive.mount('/content/drive')\n",
    "drive_path = Path(f'/content/drive/My Drive/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Input Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FARM_LOCATION = ''\n",
    "MWS_OF_FARM = ''\n",
    "DEPRESSIONLESS_DEM = ''\n",
    "HYDRAULIC_CONDUCTIVITY = ''\n",
    "OUTPUT_FOLDER_PATH = ''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utility Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_shapefiles(point_path, polygon_path):\n",
    "    \"\"\"\n",
    "    Load point (Farm Location) and polygon (Microwatershed boundary) shapefiles\n",
    "    and align their Coordinate Reference Systems (CRS).\n",
    "    \n",
    "    Parameters:\n",
    "        point_path (str): File path to the point shapefile.\n",
    "        polygon_path (str): File path to the polygon shapefile.\n",
    "    \n",
    "    Returns:\n",
    "        tuple: GeoDataFrames of points and polygons with aligned CRS.\n",
    "    \"\"\"\n",
    "    point_gdf = gpd.read_file(point_path)\n",
    "    polygon_gdf = gpd.read_file(polygon_path)\n",
    "    \n",
    "    # Align CRS\n",
    "    if point_gdf.crs != polygon_gdf.crs:\n",
    "        point_gdf = point_gdf.to_crs(polygon_gdf.crs)\n",
    "    \n",
    "    return point_gdf, polygon_gdf\n",
    "\n",
    "def get_containing_polygon(point_gdf, polygon_gdf):\n",
    "    \"\"\"\n",
    "    Identify and return the polygon geometry that contains a given point.\n",
    "    \n",
    "    Assumes only one point in point_gdf.\n",
    "\n",
    "    Parameters:\n",
    "        point_gdf (GeoDataFrame): GeoDataFrame containing a single point.\n",
    "        polygon_gdf (GeoDataFrame): GeoDataFrame containing polygon geometries.\n",
    "    \n",
    "    Returns:\n",
    "        dict or None: The geometry of the containing polygon in GeoJSON format, or None if no match.\n",
    "    \"\"\"\n",
    "    # Extract the first (and assumed only) point geometry\n",
    "    point = point_gdf.geometry.iloc[0]\n",
    "    \n",
    "    # Filter polygons that contain the point\n",
    "    containing = polygon_gdf[polygon_gdf.contains(point)]\n",
    "    \n",
    "    # Return None if no containing polygon is found\n",
    "    if containing.empty:\n",
    "        return None\n",
    "\n",
    "    # Return the containing polygon geometry as GeoJSON\n",
    "    return containing.geometry.iloc[0].__geo_interface__\n",
    "\n",
    "\n",
    "def clip_raster_with_polygon(raster_path, polygon_geom):\n",
    "    \"\"\"\n",
    "    Clip a raster file using the given polygon geometry.\n",
    "\n",
    "    Parameters:\n",
    "        raster_path (str): Path to the input raster file.\n",
    "        polygon_geom (dict): Polygon geometry in GeoJSON-like format.\n",
    "\n",
    "    Returns:\n",
    "        tuple: A tuple containing:\n",
    "            - out_image (np.ndarray): Clipped raster data.\n",
    "            - out_meta (dict): Updated raster metadata.\n",
    "            - nodata_value (float): NoData value used in the raster.\n",
    "    \"\"\"\n",
    "    with rasterio.open(raster_path) as src:\n",
    "        # Clip raster using the polygon geometry\n",
    "        out_image, out_transform = mask(src, [polygon_geom], crop=True)\n",
    "        \n",
    "        # Copy and update metadata for the output raster\n",
    "        out_meta = src.meta.copy()\n",
    "        nodata_value = src.nodata if src.nodata is not None else 0\n",
    "\n",
    "    # Update metadata with new dimensions and transform\n",
    "    out_meta.update({\n",
    "        \"height\": out_image.shape[1],\n",
    "        \"width\": out_image.shape[2],\n",
    "        \"transform\": out_transform\n",
    "    })\n",
    "    \n",
    "    return out_image, out_meta, nodata_value\n",
    "\n",
    "\n",
    "def save_raster(output_path, out_image, out_meta):\n",
    "    \"\"\"\n",
    "    Save a raster array to disk with given metadata.\n",
    "\n",
    "    Parameters:\n",
    "        output_path (str): Destination path for the output raster.\n",
    "        out_image (np.ndarray): Raster image array to save.\n",
    "        out_meta (dict): Metadata for the output raster.\n",
    "    \"\"\"\n",
    "    with rasterio.open(output_path, \"w\", **out_meta) as dest:\n",
    "        dest.write(out_image)\n",
    "\n",
    "\n",
    "def get_slope(dem=None, dem_path=None):\n",
    "    \"\"\"\n",
    "    Compute slope in degrees from a Digital Elevation Model (DEM).\n",
    "\n",
    "    Parameters:\n",
    "        dem (gdal.Dataset, optional): GDAL raster dataset object.\n",
    "        dem_path (str, optional): File path to the DEM if 'dem' is not provided.\n",
    "\n",
    "    Returns:\n",
    "        np.ndarray: 2D array representing slope in degrees.\n",
    "    \"\"\"\n",
    "    # Load DEM from file path if not directly provided\n",
    "    if dem is None:\n",
    "        if dem_path is None:\n",
    "            raise ValueError(\"Either 'dem' or 'dem_path' must be provided.\")\n",
    "        else:\n",
    "            dem = gdal.Open(dem_path)\n",
    "    \n",
    "    if dem is None:\n",
    "        raise FileNotFoundError(f\"DEM file not found: {dem_path}\")\n",
    "\n",
    "    # Perform slope calculation in memory using GDAL\n",
    "    slope_ds = gdal.DEMProcessing('', dem, 'slope', format='MEM', slopeFormat='degree')\n",
    "\n",
    "    # Read the slope band into a NumPy array\n",
    "    slope_array = slope_ds.GetRasterBand(1).ReadAsArray()\n",
    "\n",
    "    return slope_array\n",
    "\n",
    "\n",
    "def get_row_col_from_point_gdf(point_gdf, transform):\n",
    "    \"\"\"\n",
    "    Get (row, col) index in raster array for the first point in point_gdf.\n",
    "\n",
    "    Parameters:\n",
    "        - point_gdf: GeoDataFrame with a single point geometry\n",
    "        - transform: Affine transform of the raster\n",
    "\n",
    "    Returns:\n",
    "        - (row, col): Tuple of raster array indices\n",
    "    \"\"\"\n",
    "    if point_gdf.empty:\n",
    "        raise ValueError(\"The point GeoDataFrame is empty.\")\n",
    "    point_geom = point_gdf.geometry.iloc[0]\n",
    "    row, col = rowcol(transform, point_geom.x, point_geom.y)\n",
    "    return row, col\n",
    "\n",
    "\n",
    "def compute_flow_transfer_cost(slope_array, k_array, slope_nodata=None, k_nodata=None):\n",
    "    \"\"\"\n",
    "    Compute pixel-wise: 30 / (K * slope)\n",
    "    Inputs:\n",
    "        - slope_array: NumPy array of slope values\n",
    "        - k_array: NumPy array of K values\n",
    "        - slope_nodata: optional nodata value for slope\n",
    "        - k_nodata: optional nodata value for K\n",
    "    Returns:\n",
    "        - result_array: NumPy array with computed values\n",
    "        - mask: Boolean array where output is valid\n",
    "    \"\"\"\n",
    "    assert slope_array.shape == k_array.shape, \"Input arrays must have the same shape\"\n",
    "\n",
    "    # Create mask for invalid pixels\n",
    "    mask = np.ones_like(slope_array, dtype=bool)\n",
    "    if slope_nodata is not None:\n",
    "        mask &= (slope_array != slope_nodata)\n",
    "    if k_nodata is not None:\n",
    "        mask &= (k_array != k_nodata)\n",
    "    mask &= (slope_array != 0) & (k_array != 0)\n",
    "\n",
    "    # Initialize output array\n",
    "    result = np.full_like(slope_array, fill_value=np.nan, dtype=np.float32)\n",
    "\n",
    "    # Compute ratio where valid\n",
    "    with np.errstate(divide='ignore', invalid='ignore'):\n",
    "        result[mask] = 30.0 / (k_array[mask] * slope_array[mask])\n",
    "\n",
    "    return result, mask\n",
    "\n",
    "\n",
    "def get_upstream_catchment_path_distance(elevation, ft_cost, start_row, start_col, threshold=120):\n",
    "    \"\"\"\n",
    "    Identify upstream catchment area based on elevation and a cost threshold using path-based traversal.\n",
    "    \n",
    "    Parameters:\n",
    "        elevation (np.ndarray): 2D array of elevation values.\n",
    "        ft_cost (np.ndarray): 2D array representing foot travel cost at each cell.\n",
    "        start_row (int): Row index of the starting point (typically the pour point).\n",
    "        start_col (int): Column index of the starting point.\n",
    "        threshold (float): Maximum cumulative foot travel cost to allow for upstream expansion.\n",
    "\n",
    "    Returns:\n",
    "        np.ndarray: Binary mask of the upstream catchment area (1 = included, 0 = excluded).\n",
    "    \"\"\"\n",
    "    rows, cols = elevation.shape\n",
    "    \n",
    "    # Track visited cells to avoid repeated processing\n",
    "    visited = np.zeros_like(elevation, dtype=bool)\n",
    "    \n",
    "    # Output mask for catchment area\n",
    "    catchment = np.zeros_like(elevation, dtype=np.uint8)\n",
    "\n",
    "    # Define relative indices for 8-neighborhood (diagonal + orthogonal)\n",
    "    neighbors = [(-1, -1), (-1, 0), (-1, 1),\n",
    "                 (0, -1),          (0, 1),\n",
    "                 (1, -1),  (1, 0),  (1, 1)]\n",
    "\n",
    "    # Initialize BFS queue with the starting point and zero cost\n",
    "    queue = deque()\n",
    "    queue.append((start_row, start_col, 0))\n",
    "    \n",
    "    visited[start_row, start_col] = True\n",
    "    catchment[start_row, start_col] = 1\n",
    "\n",
    "    # Breadth-First Search traversal with cost-based constraint\n",
    "    while queue:\n",
    "        r, c, curr_ft_cost = queue.popleft()\n",
    "\n",
    "        # Stop traversal if cumulative cost exceeds the threshold\n",
    "        if curr_ft_cost >= threshold:\n",
    "            continue\n",
    "\n",
    "        for dr, dc in neighbors:\n",
    "            nr, nc = r + dr, c + dc\n",
    "            # Check bounds and whether cell is already visited\n",
    "            if 0 <= nr < rows and 0 <= nc < cols and not visited[nr, nc]:\n",
    "                # Only move to upstream (equal or higher elevation) cells\n",
    "                if elevation[nr, nc] >= elevation[r, c]:\n",
    "                    visited[nr, nc] = True\n",
    "                    catchment[nr, nc] = 1\n",
    "                    queue.append((nr, nc, curr_ft_cost + ft_cost[nr, nc]))\n",
    "\n",
    "    return catchment\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Upstream Catchment Delineation\n",
    "This block performs the full upstream catchment delineation for a given farm location. It first identifies the containing microwatershed and clips relevant raster layers (DEM and hydraulic conductivity) to this boundary. It then computes slope and flow transfer cost for each pixel, locates the farm in raster space, and identifies all upstream cells using a cost-constrained path traversal. Finally, it saves the resulting upstream catchment as a raster file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load farm location and microwatershed (MWS) shapefiles\n",
    "farm_location_gdf, mws_gdf = load_shapefiles(FARM_LOCATION, MWS_OF_FARM)\n",
    "\n",
    "# Identify the microwatershed polygon containing the farm location\n",
    "containing_mws_geom = get_containing_polygon(farm_location_gdf, mws_gdf)\n",
    "\n",
    "# Exit early if farm location is not within any microwatershed\n",
    "if containing_mws_geom is None:\n",
    "    print(\"No mws contains the farm location.\")\n",
    "    exit()\n",
    "\n",
    "# Clip the depressionless DEM to the containing microwatershed geometry\n",
    "dem, dem_meta, dem_nodata = clip_raster_with_polygon(DEPRESSIONLESS_DEM, containing_mws_geom)\n",
    "\n",
    "# Compute slope from the clipped DEM\n",
    "slope = get_slope(dem)\n",
    "\n",
    "# Clip the hydraulic conductivity raster to the same microwatershed\n",
    "k_array, k_meta, k_nodata = clip_raster_with_polygon(HYDRAULIC_CONDUCTIVITY, containing_mws_geom)\n",
    "\n",
    "# Compute flow transfer cost based on slope and hydraulic conductivity\n",
    "ft_cost, mask = compute_flow_transfer_cost(slope, k_array, dem_nodata, k_nodata)\n",
    "\n",
    "# Get the row and column index of the farm point in the raster grid\n",
    "transform = dem_meta['transform']\n",
    "row, col = get_row_col_from_point_gdf(farm_location_gdf, transform)\n",
    "\n",
    "# Identify upstream catchment area using elevation and cost constraints\n",
    "catchment = get_upstream_catchment_path_distance(dem, ft_cost, row, col)\n",
    "\n",
    "# Define output file path for saving the catchment raster\n",
    "output_path = Path(OUTPUT_FOLDER_PATH) / 'upstream_catchment.tif'\n",
    "\n",
    "# Prepare metadata for saving the catchment raster\n",
    "catchment_meta = dem_meta.copy()\n",
    "catchment_meta.update({\n",
    "    'dtype': 'uint8',   # Since catchment is a binary mask\n",
    "    'nodata': 0         # Use 0 to represent absence of catchment\n",
    "})\n",
    "\n",
    "# Save the catchment area as a raster file\n",
    "save_raster(output_path, catchment, catchment_meta)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
